{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 17 - Motor Control\n",
    "### Introduction to modeling and simulation of human movement\n",
    "https://github.com/BMClab/bmc/blob/master/courses/ModSim2018.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desiree Miraldo\n",
    "\n",
    "* Task (for Lecture 18):\n",
    "\n",
    "Solve problemas 1 and 2 of the notebook [Optimization (Marcos Duarte)](http://nbviewer.jupyter.org/github/BMClab/bmc/blob/master/notebooks/Optimization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Python libraries\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym\n",
    "from sympy.plotting import plot\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.core.display import Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Find the extrema in the function $f(x)=x^3-7.5x^2+18x-10$ analytically and determine if they are minimum or maximum.  \n",
    "2. Find the minimum in the $f(x)=x^3-7.5x^2+18x-10$ using the gradient descent algorithm.  \n",
    "2. Regarding the distribution problem for the elbow muscles presented in this text:  \n",
    "    a. Test different initial values for the optimization.  \n",
    "    b. Test other values for the elbow angle where the results are likely to change.   \n",
    "    \n",
    "3. In an experiment to estimate forces of the elbow flexors, through inverse dynamics it was found an elbow flexor moment of 10 Nm.  \n",
    "Consider the following data for maximum force (F0), moment arm (r), and pcsa (A) of the brachialis, brachioradialis, and biceps brachii muscles: F0 (N): 1000, 250, 700; r (cm): 2, 5, 4; A (cm$^2$): 33, 8, 23, respectively (data from Robertson et al. (2013)).  \n",
    "    a. Use static optimization to estimate the muscle forces.  \n",
    "    b. Test the robustness of the results using different initial values for the muscle forces.  \n",
    "    c. Compare the results for different cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises 1: Find the extrema in the function $f(x)=x^3-7.5x^2+18x-10$ analytically and determine if they are minimum or maximum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$Roots:\\left [ 2.0, \\quad 3.0\\right ]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = sym.symbols('x')\n",
    "f = x**3 - 7.5*x**2 + 18*x - 10\n",
    "fdiff = sym.expand(sym.diff(f, x))\n",
    "roots = sym.solve(fdiff, x)\n",
    "display(Math(sym.latex('Roots:') + sym.latex(roots)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x = 2.0) = 4.00\n",
      "f(x = 3.0) = 3.50\n"
     ]
    }
   ],
   "source": [
    "f  = lambda x: x**3 - 7.5*x**2 + 18*x - 10\n",
    "\n",
    "print('f(x = {:.1f}) = {:.2f}'.format(roots[0],f(roots[0])))\n",
    "print('f(x = {:.1f}) = {:.2f}'.format(roots[1],f(roots[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises 2: Find the minimum in the $f(x)=x^3-7.5x^2+18x-10$ using the gradient descent algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True local minimum at 3 with function value 3.5.\n",
      "Local minimum by gradient descent at 3.000323195755751 with function value 3.5000001567170003.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -4150663493044532703920128.000000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: array([ -4.15066349e+24])\n",
       "     jac: array([ 0.])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 93\n",
       "     nit: 3\n",
       "    njev: 31\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ -1.60708619e+08])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://en.wikipedia.org/wiki/Gradient_descent\n",
    "# The local minimum of $f(x)=x^3-7.5x^2+18x-10$\n",
    "\n",
    "cur_x = 6               # The algorithm starts at x=6\n",
    "gamma = 0.01            # step size multiplier\n",
    "precision = 0.00001\n",
    "step_size = 1           # initial step size\n",
    "max_iters = 10000       # maximum number of iterations\n",
    "iters = 0               # iteration counter\n",
    "\n",
    "f  = lambda x: x**3 - 7.5*x**2 + 18*x - 10  # lambda function for f(x)\n",
    "df = lambda x: 3*x**2 - 15*x + 18    # lambda function for the gradient of f(x)\n",
    "\n",
    "while (step_size > precision) and (iters < max_iters):\n",
    "    prev_x = cur_x\n",
    "    cur_x -= gamma*df(prev_x)\n",
    "    step_size = abs(cur_x - prev_x)\n",
    "    iters+=1\n",
    "\n",
    "print('True local minimum at {} with function value {}.'.format(3, f(3)))\n",
    "print('Local minimum by gradient descent at {} with function value {}.'.format(cur_x, f(cur_x)))\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "minimize(f, 6, args=(), method='CG', jac=None, tol=precision, callback=None,\n",
    "         options={'gtol': 1e-05, 'norm': np.inf, 'eps': 1.4901161193847656e-08,\n",
    "                  'maxiter': max_iters, 'disp': True, 'return_all': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
